id: s3_trigger_script
namespace: company.team
description: Process CSV file from S3 trigger

tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: python
        type: io.kestra.plugin.scripts.python.Script
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
        containerImage: ghcr.io/kestra-io/pydata:latest
        inputFiles:
          data.csv: "{{ trigger.objects | jq('.[].uri') | first }}"
        warningOnStdErr: false
        script: |
          import pandas as pd

          df = pd.read_csv("data.csv")

          # Replace non-numeric age values with NaN
          df['Age'] = pd.to_numeric(df['Age'], errors='coerce')

          # mean imputation: fill NaN values with the mean age
          mean_age = int(df['Age'].mean())
          print(f"Filling NULL values with mean: {mean_age}")
          df['Age'] = df['Age'].fillna(mean_age)
          df.to_csv("clean_dataset.csv", index=False)
        outputFiles:
          - clean_dataset.csv

triggers:
  - id: wait_for_s3_object
    type: io.kestra.plugin.aws.s3.Trigger
    bucket: declarative-orchestration
    region: "{{ secret('AWS_DEFAULT_REGION') }}"
    maxKeys: 1
    interval: PT1S
    filter: FILES
    action: MOVE
    prefix: raw/
    moveTo:
      key: archive/raw/
    accessKeyId: "{{ secret('AWS_ACCESS_KEY_ID') }}"
    secretKeyId: "{{ secret('AWS_SECRET_ACCESS_KEY') }}"
