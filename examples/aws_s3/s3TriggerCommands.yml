id: s3_trigger_commands
namespace: company.team
description: Process CSV file from S3 trigger

tasks:
  - id: wdir
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: clone_repo
        type: io.kestra.plugin.git.Clone
        url: https://github.com/kestra-io/examples
        branch: main

      - id: python
        type: io.kestra.plugin.scripts.python.Commands
        description: this script expects to. receive a file `data.csv` as input from S3 trigger
        inputFiles:
          data.csv: "{{ trigger.objects | jq('.[].uri') | first }}"
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
        containerImage: ghcr.io/kestra-io/pydata:latest
        warningOnStdErr: false
        commands:
          - python scripts/clean_messy_dataset.py
        outputFiles:
          - clean_dataset.csv

triggers:
  - id: wait_for_s3_object
    type: io.kestra.plugin.aws.s3.Trigger
    bucket: declarative-orchestration
    region: "{{ secret('AWS_DEFAULT_REGION') }}"
    maxKeys: 1
    interval: PT1S
    filter: FILES
    action: MOVE
    prefix: raw/
    moveTo:
      key: archive/raw/
    accessKeyId: "{{ secret('AWS_ACCESS_KEY_ID') }}"
    secretKeyId: "{{ secret('AWS_SECRET_ACCESS_KEY') }}"
