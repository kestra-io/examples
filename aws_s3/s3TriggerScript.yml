id: s3TriggerScript
namespace: blueprint
description: process CSV file from S3 trigger

tasks:
  - id: wdir
    type: io.kestra.core.tasks.flows.WorkingDirectory
    tasks:
      - id: local
        type: io.kestra.core.tasks.storages.LocalFiles
        inputs:
          data.csv: "{{ trigger.objects | jq('.[].uri') | first }}"

      - id: python
        type: io.kestra.plugin.scripts.python.Script
        runner: DOCKER
        docker:
          image: ghcr.io/kestra-io/pydata:latest
        warningOnStdErr: false
        script: |
          import pandas as pd

          df = pd.read_csv("data.csv")

          # Replace non-numeric age values with NaN
          df['Age'] = pd.to_numeric(df['Age'], errors='coerce')

          # mean imputation: fill NaN values with the mean age
          mean_age = int(df['Age'].mean())
          print(f"Filling NULL values with mean: {mean_age}")
          df['Age'] = df['Age'].fillna(mean_age)
          df.to_csv("clean_dataset.csv", index=False)

      - id: output
        type: io.kestra.core.tasks.storages.LocalFiles
        outputs:
          - clean_dataset.csv

triggers:
  - id: waitForS3object
    type: io.kestra.plugin.aws.s3.Trigger
    bucket: declarative-orchestration
    region: "{{ secret('AWS_DEFAULT_REGION') }}"
    maxKeys: 1
    interval: PT1S
    filter: FILES
    action: MOVE
    prefix: raw/
    moveTo:
      key: archive/raw/
    accessKeyId: "{{ secret('AWS_ACCESS_KEY_ID') }}"
    secretKeyId: "{{ secret('AWS_SECRET_ACCESS_KEY') }}"
